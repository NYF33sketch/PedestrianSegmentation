{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from numpy import *\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import shutil\n",
    "import sys,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_path = 'D:/workspace/Projects/vae/PedCut2013_SegmentationDataset/data/completeData/left_images/'\n",
    "total_label_path = 'D:/workspace/Projects/vae/PedCut2013_SegmentationDataset/data/completeData/left_groundTruth/'\n",
    "val_data_path = 'D:/workspace/Projects/vae/PedCut2013_SegmentationDataset/data/validationData/left_images'\n",
    "val_label_path = 'D:/workspace/Projects/vae/PedCut2013_SegmentationDataset/data/validationData/left_groundTruth'\n",
    "\n",
    "test_data_path = 'D:/workspace/Projects/vae/PedCut2013_SegmentationDataset/data/testData/left_images'\n",
    "test_label_path = 'D:/workspace/Projects/vae/PedCut2013_SegmentationDataset/data/testData/left_groundTruth'\n",
    "total_pngs = glob.glob(total_data_path+\"/*.png\")\n",
    "val_pngs = glob.glob(val_data_path+\"/*.png\")\n",
    "test_pngs = glob.glob(test_data_path+\"/*.png\")\n",
    "val_imgs = os.listdir(val_data_path)\n",
    "test_imgs = os.listdir(test_data_path)\n",
    "train_path = 'D:/workspace/Projects/vae/PedCut2013_SegmentationDataset/data/trainData/'\n",
    "train_pngs = []\n",
    "max_pixels = 0\n",
    "min_pixels = inf\n",
    "pixels = []\n",
    "for png in total_pngs:\n",
    "    tag = png.split('\\\\')[-1]\n",
    "    if (tag not in val_imgs) and (tag not in test_imgs):\n",
    "        src_ground_truth = png.replace(\"left_images\",\"left_groundTruth\")\n",
    "        src_image = png\n",
    "        dst_ground_truth = train_path+\"left_groundTruth/\" + tag\n",
    "        dst_image = train_path+\"left_images/\"+tag\n",
    "        train_pngs.append(png)\n",
    "        shutil.copy(src=src_ground_truth,dst=dst_ground_truth)\n",
    "        shutil.copy(src=src_image,dst=dst_image)\n",
    "        \n",
    "#     img = cv2.imread(png)\n",
    "#     p = img.shape[0]*img.shape[1]\n",
    "#     if max_pixels < p: max_pixels = p\n",
    "#     if min_pixels > p: min_pixels = p\n",
    "#     pixels.append([img.shape[0], img.shape[1]])\n",
    "\n",
    "# pixels = array(pixels)\n",
    "# ratios = []\n",
    "# for height, width in (zip(pixels[:,0],pixels[:,1])):\n",
    "#     ratio = height/width\n",
    "#     ratios.append(ratio)\n",
    "\n",
    "# ratio = sorted(ratios)[int(len(ratios)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(volume):\n",
    "    mean = volume.mean()\n",
    "    std = volume.std()\n",
    "    out = (volume - mean)/(std+1e-20)\n",
    "    out_random = zeros(volume.shape)\n",
    "    out[volume == 0] = out_random[volume ==0]\n",
    "    return out\n",
    "\n",
    "\n",
    "def default_loader(image, label, ratio, width, train_set): \n",
    "\n",
    "    image = cv2.imread(image)\n",
    "    mask = cv2.imread(label)\n",
    "    new_size = (int(width * ratio), width)\n",
    "    old_height, old_width, _ = image.shape\n",
    "    assert(old_height == mask.shape[0])\n",
    "    assert(old_width == mask.shape[1])\n",
    "    \n",
    "    height_ = int(old_width * ratio)\n",
    "    if old_height < height_:\n",
    "        padding = height_ - old_height\n",
    "        padding_array = zeros((padding, old_width,3))\n",
    "        image = concatenate((image, padding_array),0)\n",
    "        mask = concatenate((mask, padding_array), 0)\n",
    "    else:\n",
    "        cutting = int(round((old_height - height_)/2))\n",
    "        image = image[cutting: old_height-cutting]\n",
    "        mask = mask[cutting: old_height-cutting]\n",
    "    \n",
    "    x_ratio = new_size[1] / image.shape[1]\n",
    "    y_ratio = new_size[0] / image.shape[0]\n",
    "    \n",
    "    image = cv2.resize(image, (0, 0), fx=x_ratio, fy=y_ratio, interpolation=cv2.INTER_NEAREST)\n",
    "    mask = cv2.resize(mask, (0, 0), fx=x_ratio, fy=y_ratio, interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    image = image.transpose(2, 0, 1)\n",
    "    mask = mask[:,:,0].astype(float)\n",
    "    mask[mask==255] = 1.\n",
    "    return normalize(image), mask\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, files, ratio, width, label_path, train_set, loader = default_loader):\n",
    "        \n",
    "        image_label = []\n",
    "        for file_ in files:\n",
    "            tag = file_.split('\\\\')[-1]\n",
    "            mask_name = label_path + tag\n",
    "            image_label.append((file_, mask_name))\n",
    "        self.image_label = image_label\n",
    "        self.train_set = train_set\n",
    "        self.loader = loader\n",
    "        self.ratio = ratio\n",
    "        self.width = width\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.image_label[index]\n",
    "        image, label = self.loader(image, label, self.ratio, self.width, self.train_set)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_label)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Encoder, self).__init__()\n",
    "        #conv1\n",
    "        self.conv1_1 = nn.Conv2d(3, 16, 3,padding=1)\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/2\n",
    "        \n",
    "        # conv2\n",
    "        self.conv2_1 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/4\n",
    "        \n",
    "        # conv3\n",
    "        self.conv3_1 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/8\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1_1(x)\n",
    "        \n",
    "        x = self.relu1_1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2_1(x)\n",
    "        x = self.relu2_1(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3_1(x)\n",
    "        x = self.relu3_1(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # upConv3\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2)\n",
    "        self.upconv1_1 = nn.Conv2d(64,32, 3,padding=1)\n",
    "        self.BN1 = nn.BatchNorm2d(32)\n",
    "        self.uprelu1_1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # upConv2\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2)\n",
    "        self.upconv2_1 = nn.Conv2d(32,32, 3,padding=1)\n",
    "        self.BN2 = nn.BatchNorm2d(32)\n",
    "        self.uprelu2_1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        \n",
    "        # upConv1\n",
    "        self.upsample3 = nn.Upsample(scale_factor=2)\n",
    "        self.upconv3_1 = nn.Conv2d(32,32, 3,padding=1)\n",
    "        self.BN3 = nn.BatchNorm2d(32)\n",
    "        self.uprelu3_1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv = nn.Conv2d(32, 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.upsample1(x)\n",
    "        x = self.upconv1_1(x)\n",
    "        x = self.BN1(x)\n",
    "        x = self.uprelu1_1(x)\n",
    "        \n",
    "        x = self.upsample2(x)\n",
    "        x = self.upconv2_1(x)\n",
    "        x = self.BN2(x)\n",
    "        x = self.uprelu2_1(x)\n",
    "        \n",
    "        x = self.upsample3(x)\n",
    "        x = self.upconv3_1(x)\n",
    "        x = self.BN3(x)\n",
    "        x = self.uprelu3_1(x)\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class net(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(net, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2, 200, 96])\n"
     ]
    }
   ],
   "source": [
    "model = net()\n",
    "x = torch.ones((8,3,200,96))\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_binary_dice(input, target, eps = 0.000001):\n",
    "    assert(input.shape == target.shape)\n",
    "    input = input.float()\n",
    "    target = target.float()\n",
    "    N = target.size(0)\n",
    "    input_flat = input.view(N, -1)\n",
    "    target_flat = target.view(N, -1)\n",
    "    intersaction = input_flat * target_flat\n",
    "    dice = (2*intersaction.sum(1) + eps) / (input_flat.sum(1)+target_flat.sum(1)+eps)\n",
    "    return dice.sum()/N\n",
    "\n",
    "class multiclass_dice_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(multiclass_dice_loss, self).__init__()\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        input = input[:,1,...]\n",
    "        input = input.unsqueeze(1)\n",
    "        \n",
    "        dice = torch_binary_dice(input, target, eps=0.000001)\n",
    "        return 1 - dice\n",
    "\n",
    "    \n",
    "def evaluation(model, val_loader, epoch, dice_loss):\n",
    "    model.eval()\n",
    "    total_dice = 0\n",
    "    num_batch_processed=0\n",
    "    total_loss = 0\n",
    "    for step,(b_x,gt) in enumerate(val_loader):\n",
    "        \n",
    "        b_x.resize_(b_x.shape[0],3,b_x.shape[2],b_x.shape[3])\n",
    "        gt.resize_(gt.shape[0],1,gt.shape[1],gt.shape[2])\n",
    "        \n",
    "        b_x = b_x.float()\n",
    "        gt = gt.float()\n",
    "        output = model(b_x)\n",
    "        output_softmax = F.softmax(output, dim=1)\n",
    "        loss= dice_loss(output_softmax,gt)\n",
    "        dice = 1-loss\n",
    "        total_dice += dice\n",
    "        total_loss += loss\n",
    "        num_batch_processed += 1\n",
    "    mean_dice = total_dice/(num_batch_processed+1)\n",
    "    mean_loss = total_loss/(num_batch_processed+1)\n",
    "        \n",
    "    return mean_dice, mean_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, train_data,val_data, batch_size, lr):\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size,shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_data, batch_size=1,shuffle=False)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "    dice_loss = multiclass_dice_loss()\n",
    "    best_eval_loss = 999\n",
    "    total_iterations_per_epoch = (train_data.__len__()//batch_size) + 1\n",
    "    \n",
    "    for epoch in range(20):\n",
    "        print('    ----- training epoch {} -----'.format(epoch+1))\n",
    "        model.train()\n",
    "        loss_epoch = 0.0\n",
    "        num_batch_processed = 0\n",
    "        \n",
    "        for step, (b_x, b_y) in enumerate(train_loader):\n",
    "            \n",
    "            percentage = int(step/total_iterations_per_epoch*100)\n",
    "            str = '>'*(step//2)+' '*((total_iterations_per_epoch-step)//2)\n",
    "            sys.stdout.write('\\r'+str+'[%s%%]'%(percentage+1))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            b_x.resize_(b_x.shape[0],3,b_x.shape[2],b_x.shape[3])\n",
    "            b_y.resize_(b_y.shape[0],1,b_y.shape[1],b_y.shape[2])\n",
    "            \n",
    "            b_x = b_x.float()\n",
    "            b_y = b_y.float()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(b_x)\n",
    "            \n",
    "            output_softmax = F.softmax(output, dim=1)\n",
    "            loss = dice_loss(output_softmax,b_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_epoch += loss.item()\n",
    "            num_batch_processed += 1\n",
    "            \n",
    "        loss_epoch /= num_batch_processed\n",
    "        print(\"epoch {} train loss: {} train dice {}\\n\".format(epoch+1, loss, 1-loss))\n",
    "        eval_dice,eval_loss = evaluation(model, val_loader, epoch, dice_loss)\n",
    "        print(\"epoch {} validation loss: {} eval dice {}\\n\".format(epoch+1, eval_loss, eval_dice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ----- training epoch 1 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 1 train loss: 0.39857012033462524 train dice 0.6014298796653748\n",
      "\n",
      "epoch 1 validation loss: 0.5208099484443665 eval dice 0.446931928396225\n",
      "\n",
      "    ----- training epoch 2 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 2 train loss: 0.35781192779541016 train dice 0.6421880722045898\n",
      "\n",
      "epoch 2 validation loss: 0.39401817321777344 eval dice 0.5737237334251404\n",
      "\n",
      "    ----- training epoch 3 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 3 train loss: 0.32251864671707153 train dice 0.6774813532829285\n",
      "\n",
      "epoch 3 validation loss: 0.37292781472206116 eval dice 0.5948140621185303\n",
      "\n",
      "    ----- training epoch 4 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 4 train loss: 0.32284027338027954 train dice 0.6771597266197205\n",
      "\n",
      "epoch 4 validation loss: 0.3527725338935852 eval dice 0.6149693727493286\n",
      "\n",
      "    ----- training epoch 5 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 5 train loss: 0.2338932752609253 train dice 0.7661067247390747\n",
      "\n",
      "epoch 5 validation loss: 0.33316466212272644 eval dice 0.634577214717865\n",
      "\n",
      "    ----- training epoch 6 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 6 train loss: 0.2860807180404663 train dice 0.7139192819595337\n",
      "\n",
      "epoch 6 validation loss: 0.36527886986732483 eval dice 0.6024631261825562\n",
      "\n",
      "    ----- training epoch 7 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 7 train loss: 0.24031132459640503 train dice 0.759688675403595\n",
      "\n",
      "epoch 7 validation loss: 0.32457172870635986 eval dice 0.643170177936554\n",
      "\n",
      "    ----- training epoch 8 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 8 train loss: 0.24424415826797485 train dice 0.7557558417320251\n",
      "\n",
      "epoch 8 validation loss: 0.3015156686306 eval dice 0.6662261486053467\n",
      "\n",
      "    ----- training epoch 9 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 9 train loss: 0.24243736267089844 train dice 0.7575626373291016\n",
      "\n",
      "epoch 9 validation loss: 0.292819619178772 eval dice 0.6749224066734314\n",
      "\n",
      "    ----- training epoch 10 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 10 train loss: 0.21397799253463745 train dice 0.7860220074653625\n",
      "\n",
      "epoch 10 validation loss: 0.28333866596221924 eval dice 0.6844032406806946\n",
      "\n",
      "    ----- training epoch 11 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 11 train loss: 0.2109639048576355 train dice 0.7890360951423645\n",
      "\n",
      "epoch 11 validation loss: 0.2930380702018738 eval dice 0.67470383644104\n",
      "\n",
      "    ----- training epoch 12 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 12 train loss: 0.1760072112083435 train dice 0.8239927887916565\n",
      "\n",
      "epoch 12 validation loss: 0.28571566939353943 eval dice 0.6820262670516968\n",
      "\n",
      "    ----- training epoch 13 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 13 train loss: 0.18553388118743896 train dice 0.814466118812561\n",
      "\n",
      "epoch 13 validation loss: 0.27402588725090027 eval dice 0.6937159895896912\n",
      "\n",
      "    ----- training epoch 14 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 14 train loss: 0.19589078426361084 train dice 0.8041092157363892\n",
      "\n",
      "epoch 14 validation loss: 0.26351940631866455 eval dice 0.7042224407196045\n",
      "\n",
      "    ----- training epoch 15 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 15 train loss: 0.2096368670463562 train dice 0.7903631329536438\n",
      "\n",
      "epoch 15 validation loss: 0.25685420632362366 eval dice 0.7108877301216125\n",
      "\n",
      "    ----- training epoch 16 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 16 train loss: 0.18953734636306763 train dice 0.8104626536369324\n",
      "\n",
      "epoch 16 validation loss: 0.26574379205703735 eval dice 0.7019979953765869\n",
      "\n",
      "    ----- training epoch 17 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 17 train loss: 0.18173158168792725 train dice 0.8182684183120728\n",
      "\n",
      "epoch 17 validation loss: 0.2603254020214081 eval dice 0.7074164152145386\n",
      "\n",
      "    ----- training epoch 18 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 18 train loss: 0.15725749731063843 train dice 0.8427425026893616\n",
      "\n",
      "epoch 18 validation loss: 0.25683343410491943 eval dice 0.7109085321426392\n",
      "\n",
      "    ----- training epoch 19 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 19 train loss: 0.19850075244903564 train dice 0.8014992475509644\n",
      "\n",
      "epoch 19 validation loss: 0.25817957520484924 eval dice 0.709562361240387\n",
      "\n",
      "    ----- training epoch 20 -----\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>[99%]epoch 20 train loss: 0.18561065196990967 train dice 0.8143893480300903\n",
      "\n",
      "epoch 20 validation loss: 0.25286462903022766 eval dice 0.7148773074150085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_path = 'D:/workspace/Projects/vae/PedCut2013_SegmentationDataset/data/trainData/left_images/'\n",
    "train_label_path = 'D:/workspace/Projects/vae/PedCut2013_SegmentationDataset/data/trainData/left_groundTruth/'\n",
    "train_pngs = glob.glob(train_path+'*.png')\n",
    "val_path = 'D:/workspace/Projects/vae/PedCut2013_SegmentationDataset/data/validationData/left_images/'\n",
    "val_label_path = 'D:/workspace/Projects/vae/PedCut2013_SegmentationDataset/data/validationData/left_groundTruth/'\n",
    "val_pngs = glob.glob(val_path+'*.png')\n",
    "train_data = Data(files=train_pngs, ratio =2.09, width=96,label_path=train_label_path, train_set=True, loader = default_loader)\n",
    "val_data = Data(files=val_pngs, ratio =2.09, width=96, label_path=val_label_path, train_set=True, loader = default_loader)\n",
    "model = net()\n",
    "trainer(model, train_data,val_data, batch_size = 8, lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}